{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from oemof import solph\n",
    "import tsam.timeseriesaggregation as tsam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(noTypicalPeriods, hoursPerPeriod, data):\n",
    "    aggregation = tsam.TimeSeriesAggregation(\n",
    "        data,\n",
    "        noTypicalPeriods=noTypicalPeriods,\n",
    "        hoursPerPeriod=hoursPerPeriod,\n",
    "        clusterMethod='k_means'\n",
    "    )\n",
    "\n",
    "    agg_data = aggregation.createTypicalPeriods()\n",
    "\n",
    "    agg_data.index.names = ['TypicalPeriod', 'TimeStep']\n",
    "    agg_data.reset_index(inplace=True)\n",
    "\n",
    "    return aggregation, agg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(agg_data):\n",
    "    timeindex = pd.date_range('2019-01-01 00:00', freq='h', periods=agg_data.shape[0])\n",
    "    es = solph.EnergySystem(\n",
    "        timeindex=timeindex, infer_last_interval=True\n",
    "    )\n",
    "\n",
    "    b_gas = solph.Bus(\"gas bus\")\n",
    "    b_electricity = solph.Bus(\"electricity bus\")\n",
    "    b_heat = solph.Bus(\"heat bus\")\n",
    "\n",
    "    source_gas = solph.components.Source(\n",
    "        \"gas source\",\n",
    "        outputs={b_gas: solph.Flow(variable_costs=agg_data[\"gas_price\"] + agg_data[\"co2_price\"])}\n",
    "    )\n",
    "    source_electricity = solph.components.Source(\n",
    "        \"electricity source\",\n",
    "        outputs={b_electricity: solph.Flow(variable_costs=agg_data[\"el_spot_price\"])}\n",
    "    )\n",
    "    sink_heat = solph.components.Sink(\n",
    "        \"heat demand\",\n",
    "        inputs={b_heat: solph.Flow(fix=agg_data[\"heat\"], nominal_value=1)}\n",
    "    )\n",
    "\n",
    "    heat_pump = solph.components.Converter(\n",
    "        label=\"heat pump\",\n",
    "        inputs={b_electricity: solph.Flow()},\n",
    "        outputs={b_heat: solph.Flow(nominal_value=100)},\n",
    "        conversion_factors={b_heat: 3.5}\n",
    "    )\n",
    "    boiler = solph.components.Converter(\n",
    "        label=\"gas boiler\",\n",
    "        inputs={b_gas: solph.Flow()},\n",
    "        outputs={b_heat: solph.Flow(nominal_value=100)},\n",
    "        conversion_factors={b_heat: 0.9}\n",
    "    )\n",
    "\n",
    "    heat_slack = solph.components.Source(\n",
    "        label=\"heat slack\",\n",
    "        outputs={b_heat: solph.Flow(variable_costs=1000)}\n",
    "    )\n",
    "\n",
    "    storage = solph.components.GenericStorage(\n",
    "        label=\"heat storage\",\n",
    "        inputs={b_heat: solph.Flow(nominal_value=50)},\n",
    "        outputs={b_heat: solph.Flow(nominal_value=50)},\n",
    "        nominal_storage_capacity=24 * 50,\n",
    "        initial_storage_level=0.5,\n",
    "        balanced=True\n",
    "    )\n",
    "\n",
    "    es.add(\n",
    "        b_gas, b_electricity, b_heat,\n",
    "        source_electricity, source_gas, sink_heat, heat_slack,\n",
    "        heat_pump, boiler, storage\n",
    "    )\n",
    "\n",
    "    model = solph.Model(es)\n",
    "\n",
    "    _ = model.solve(\"gurobi\")\n",
    "\n",
    "    results = solph.views.convert_keys_to_strings(model.results())\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(results, agg_data=None, aggregation=None):\n",
    "    unitdata = pd.DataFrame()\n",
    "    for vertex, data in results.items():\n",
    "        if vertex[-1] != 'None':\n",
    "            unitdata[' to '.join(vertex)] = data['sequences']['flow']\n",
    "        else:\n",
    "            unitdata[f'{vertex[0]} storage content'] = data['sequences']['storage_content']\n",
    "\n",
    "    if agg_data is not None and aggregation is not None:\n",
    "        unitdata = unitdata.dropna()\n",
    "        unitdata = unitdata.reset_index(drop=True)\n",
    "\n",
    "        unitdata = pd.concat([unitdata, agg_data[['TypicalPeriod', 'TimeStep']]], axis=1)\n",
    "        unitdata = unitdata.set_index(['TypicalPeriod', 'TimeStep'])\n",
    "\n",
    "        matched_indices = aggregation.indexMatching()\n",
    "\n",
    "        periods = unitdata.index.get_level_values('TypicalPeriod')\n",
    "        timesteps = unitdata.index.get_level_values('TimeStep')\n",
    "\n",
    "        unitdata_flat = pd.DataFrame(unitdata.values, columns=unitdata.columns)\n",
    "        unitdata_flat['PeriodNum'] = periods\n",
    "        unitdata_flat['TimeStep'] = timesteps\n",
    "\n",
    "        desagg_data = matched_indices.reset_index().merge(\n",
    "            unitdata_flat,\n",
    "            how='left',\n",
    "            left_on=['PeriodNum', 'TimeStep'],\n",
    "            right_on=['PeriodNum', 'TimeStep']\n",
    "        ).set_index(matched_indices.index)\n",
    "\n",
    "        desagg_data = desagg_data.drop(columns=['Date', 'PeriodNum', 'TimeStep'])\n",
    "\n",
    "        return desagg_data\n",
    "\n",
    "    else:\n",
    "        return unitdata.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_year(desagg_data, aggregation):\n",
    "    matched_indices = aggregation.indexMatching()\n",
    "\n",
    "    if desagg_data.index[0].is_leap_year:\n",
    "        nr_missing = 8784 - len(desagg_data)\n",
    "    else:\n",
    "        nr_missing = 8760 - len(desagg_data)\n",
    "\n",
    "    lastperiod = matched_indices[matched_indices['PeriodNum'] == matched_indices['PeriodNum'].iloc[-1]]\n",
    "    lastperiod.drop_duplicates(inplace=True)\n",
    "    lpdata = desagg_data.loc[lastperiod.iloc[:nr_missing].index , :]\n",
    "\n",
    "    print(lpdata.shape)\n",
    "\n",
    "    missing_index = pd.date_range(\n",
    "        start=f'{desagg_data.index[-1]+pd.Timedelta(\"1h\")}',\n",
    "        end=f'{desagg_data.index[-1].year}-12-31 23:00',\n",
    "        freq='h'\n",
    "    )\n",
    "    missing_data = pd.DataFrame(index=missing_index, data=lpdata.values, columns=lpdata.columns)\n",
    "\n",
    "    return pd.concat([desagg_data, missing_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_key_params(desagg_data, ts_in):\n",
    "    el_cost = (desagg_data['electricity source to electricity bus'].values * ts_in['el_spot_price'].values).sum()\n",
    "    gas_cost = (desagg_data['gas source to gas bus'].values * (\n",
    "        ts_in['gas_price'].values + ts_in['co2_price'].values\n",
    "    )).sum()\n",
    "    slack_cost = (desagg_data['heat slack to heat bus'].values * 1000).sum()\n",
    "\n",
    "    opex_total = el_cost + gas_cost  # + slack_cost\n",
    "\n",
    "    heat_prod_shares = (\n",
    "        desagg_data[['heat pump to heat bus', 'gas boiler to heat bus', 'heat slack to heat bus']].sum()\n",
    "        / desagg_data[['heat pump to heat bus', 'gas boiler to heat bus', 'heat slack to heat bus']].sum().sum()\n",
    "        )\n",
    "    heat_prod_shares\n",
    "\n",
    "    heat_prod_total = desagg_data['heat bus to heat demand'].sum()\n",
    "\n",
    "    return opex_total, heat_prod_shares, heat_prod_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agg_performance(noTypicalPeriods, hoursPerPeriod):\n",
    "    ts_in = pd.read_csv(\"time_series.csv\", index_col=0, parse_dates=True)\n",
    "    ts_in = ts_in.drop(columns=\"ef_om\")\n",
    "    missing_hours = ts_in.shape[0] % hoursPerPeriod\n",
    "    if missing_hours > 0:\n",
    "        ts_in = ts_in.iloc[:-missing_hours, :]\n",
    "\n",
    "    print('Perfomance Clustering & Preprocessing:')\n",
    "    %timeit aggregation, agg_data = preprocessing(noTypicalPeriods=noTypicalPeriods, hoursPerPeriod=hoursPerPeriod, data=ts_in)\n",
    "    print('Perfomance Optimization:')\n",
    "    %timeit results = optimization(agg_data=agg_data)\n",
    "    print('Perfomance Desaggregation:')\n",
    "    %timeit desagg_data = postprocessing(results=results, agg_data=agg_data, aggregation=aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization_timed(noTypicalPeriods, hoursPerPeriod):\n",
    "    ts_in = pd.read_csv(\"time_series.csv\", index_col=0, parse_dates=True)\n",
    "    ts_in = ts_in.drop(columns=\"ef_om\")\n",
    "\n",
    "    starttime = time()\n",
    "    aggregation, agg_data = preprocessing(noTypicalPeriods=noTypicalPeriods, hoursPerPeriod=hoursPerPeriod, data=ts_in)\n",
    "    aggregation_time = time() - starttime\n",
    "\n",
    "    starttime = time()\n",
    "    results = optimization(agg_data=agg_data)\n",
    "    optimization_time = time() - starttime\n",
    "\n",
    "    starttime = time()\n",
    "    desagg_data = postprocessing(results=results, agg_data=agg_data, aggregation=aggregation)\n",
    "\n",
    "    if desagg_data.index[0].is_leap_year:\n",
    "        target_hours = 8784\n",
    "        missing_hours = target_hours - len(desagg_data)\n",
    "    else:\n",
    "        target_hours = 8760\n",
    "        missing_hours = target_hours - len(desagg_data)\n",
    "\n",
    "    if missing_hours > 0:  # Is this case even occurring?\n",
    "        desagg_data = fill_year(desagg_data=desagg_data, aggregation=aggregation)\n",
    "    elif missing_hours < 0:\n",
    "        desagg_data = desagg_data.iloc[:target_hours, :]\n",
    "\n",
    "    disaggregation_time = time() - starttime\n",
    "\n",
    "    opex_total, heat_prod_shares, heat_prod_total = calc_key_params(desagg_data=desagg_data, ts_in=ts_in)\n",
    "\n",
    "    return aggregation_time, optimization_time, disaggregation_time, desagg_data, opex_total, heat_prod_shares, heat_prod_total, desagg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_in = pd.read_csv(\"time_series.csv\", index_col=0, parse_dates=True)\n",
    "ts_in = ts_in.drop(columns=\"ef_om\")\n",
    "\n",
    "results = optimization(agg_data=ts_in)\n",
    "unitdata_base = postprocessing(results)\n",
    "opex_total_base, heat_prod_shares_base, heat_prod_total_base = calc_key_params(unitdata_base, ts_in)\n",
    "\n",
    "heat_prod_shares_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opex_total_base / heat_prod_total_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_prod_total_base * 1000 * 0.0386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noTypicalPeriods = 10\n",
    "hoursPerPeriod = 168\n",
    "\n",
    "ts_in = pd.read_csv(\"time_series.csv\", index_col=0, parse_dates=True)\n",
    "ts_in = ts_in.drop(columns=\"ef_om\")\n",
    "missing_hours = ts_in.shape[0] % hoursPerPeriod\n",
    "if missing_hours > 0:\n",
    "    ts_in = ts_in.iloc[:-missing_hours, :]\n",
    "ts_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation, agg_data = preprocessing(noTypicalPeriods=noTypicalPeriods, hoursPerPeriod=hoursPerPeriod, data=ts_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = optimization(agg_data=agg_data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desagg_data = postprocessing(results=results, agg_data=agg_data, aggregation=aggregation)\n",
    "desagg_data = postprocessing(results=results, agg_data=agg_data, aggregation=aggregation)\n",
    "desagg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "ax.plot(desagg_data['heat bus to heat demand'], label='Desaggregierte Wärmeproduktion')\n",
    "ax.plot(ts_in['heat'], label='Gemessene Wärmeproduktion')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_ylabel('Stündliche Wärmeproduktion in MW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "ax.plot(desagg_data['heat storage storage content'])\n",
    "\n",
    "ax.grid()\n",
    "ax.set_ylabel('Wärmespeicherfüllstand in MWh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdiff = desagg_data[['heat pump to heat bus', 'gas boiler to heat bus', 'heat slack to heat bus']] - unitdata_base[['heat pump to heat bus', 'gas boiler to heat bus', 'heat slack to heat bus']]\n",
    "aggdiff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "ax.bar(list(range(1, len(desagg_data)+1)), desagg_data['heat pump to heat bus'], label='Einsatz desaggregiert')\n",
    "ax.bar(list(range(1, len(aggdiff)+1)), aggdiff['heat pump to heat bus'], label='Abweichung Basecase')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(axis='y')\n",
    "ax.set_ylabel('Abweichung Wärmeproduktion Wärmepumpe in MW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "ax.bar(list(range(1, len(desagg_data)+1)), desagg_data['gas boiler to heat bus'], label='Einsatz desaggregiert')\n",
    "ax.bar(list(range(1, len(aggdiff)+1)), aggdiff['gas boiler to heat bus'], label='Abweichung Basecase')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(axis='y')\n",
    "ax.set_ylabel('Abweichung Wärmeproduktion Gaskessel in MW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "ax.bar(list(range(1, len(desagg_data)+1)), desagg_data['heat slack to heat bus'], label='Einsatz desaggregiert')\n",
    "ax.bar(list(range(1, len(aggdiff)+1)), aggdiff['heat slack to heat bus'], label='Abweichung Basecase')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(axis='y')\n",
    "ax.set_ylabel('Abweichung Wärmeproduktion Wärmequelle in MW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agg_performance(noTypicalPeriods=10, hoursPerPeriod=168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "rerun = False\n",
    "overwrite = False\n",
    "\n",
    "nr_periods = list(range(1, 21))\n",
    "hours_per_period = [24, 3*24, 5*24, 7*24, 14*24]\n",
    "\n",
    "multiindex = pd.MultiIndex.from_product([hours_per_period, nr_periods])\n",
    "perf = pd.DataFrame(index=multiindex)\n",
    "keyparams = pd.DataFrame(index=multiindex)\n",
    "\n",
    "heatflows = ['heat pump to heat bus', 'gas boiler to heat bus', 'heat slack to heat bus']\n",
    "\n",
    "unit_data_all = {}\n",
    "for hour_pp in hours_per_period:\n",
    "    unit_data_all[hour_pp] = {}\n",
    "    for nr_period in nr_periods:\n",
    "        if rerun:\n",
    "            aggregation_time, optimization_time, disaggregation_time, desagg_data, opex_total, heat_prod_shares, heat_prod_total, desagg_data = run_optimization_timed(noTypicalPeriods=nr_period, hoursPerPeriod=hour_pp)\n",
    "            perf.loc[(hour_pp, nr_period), 'aggregation_time'] = aggregation_time\n",
    "            perf.loc[(hour_pp, nr_period), 'optimization_time'] = optimization_time\n",
    "            perf.loc[(hour_pp, nr_period), 'disaggregation_time'] = disaggregation_time\n",
    "            keyparams.loc[(hour_pp, nr_period), 'opex_total'] = opex_total\n",
    "            keyparams.loc[(hour_pp, nr_period), 'hp_share'] = heat_prod_shares['heat pump to heat bus']\n",
    "            keyparams.loc[(hour_pp, nr_period), 'gb_share'] = heat_prod_shares['gas boiler to heat bus']\n",
    "            keyparams.loc[(hour_pp, nr_period), 'slack_share'] = heat_prod_shares['heat slack to heat bus']\n",
    "            keyparams.loc[(hour_pp, nr_period), 'heat_prod_total'] = heat_prod_total\n",
    "            unit_data_all[hour_pp][nr_period] = desagg_data\n",
    "            keyparams.loc[(hour_pp, nr_period), 'disp_diff_total'] = (desagg_data[heatflows] - unitdata_base[heatflows]).abs().sum().sum()\n",
    "        else:\n",
    "            path = os.path.join(\"results\", f\"{hour_pp}\", f\"{nr_period}\", \"result.csv\")\n",
    "            unit_data_all[hour_pp][nr_period] = pd.read_csv(path, sep=';', index_col=0, parse_dates=True)\n",
    "\n",
    "        if overwrite:\n",
    "            path = os.path.join(\"results\", f\"{hour_pp}\", f\"{nr_period}\")\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "            unit_data_all[hour_pp][nr_period].to_csv(os.path.join(path, \"result.csv\"), sep=\";\")\n",
    "\n",
    "if rerun:\n",
    "    perf['total_time'] = perf['aggregation_time'] + perf['optimization_time'] + perf['disaggregation_time']\n",
    "else:\n",
    "    keyparams = pd.read_csv(os.path.join(\"results\", \"keyparams.csv\"), sep=\";\", index_col=[0, 1])\n",
    "    perf = pd.read_csv(os.path.join(\"results\", \"perf.csv\"), sep=\";\", index_col=[0, 1])\n",
    "\n",
    "if overwrite:\n",
    "    keyparams.to_csv(os.path.join(\"results\", \"keyparams.csv\"), sep=\";\")\n",
    "    perf.to_csv(os.path.join(\"results\", \"perf.csv\"), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_axs = len(hours_per_period)\n",
    "fig, ax = plt.subplots(nr_axs, 1, figsize=(12, 3*nr_axs))\n",
    "\n",
    "for i, hour_pp in enumerate(hours_per_period):\n",
    "    ax[i].bar(nr_periods, perf.loc[(hour_pp, nr_periods), 'aggregation_time'], label='aggregation')\n",
    "    ax[i].bar(nr_periods, perf.loc[(hour_pp, nr_periods), 'optimization_time'], label='optimization', bottom=perf.loc[(hour_pp, nr_periods), 'aggregation_time'])\n",
    "    ax[i].bar(nr_periods, perf.loc[(hour_pp, nr_periods), 'disaggregation_time'], label='disaggregation', bottom=perf.loc[(hour_pp, nr_periods), 'aggregation_time']+perf.loc[(hour_pp, nr_periods), 'optimization_time'])\n",
    "\n",
    "    ax2 = ax[i].twinx()\n",
    "    ax2.bar(\n",
    "        nr_periods, keyparams.loc[(hour_pp, nr_periods), 'opex_total']\n",
    "        /keyparams.loc[(hour_pp, nr_periods), 'heat_prod_total'],\n",
    "        width=1/3, label='opex_total', color='red'\n",
    "        )\n",
    "    ax2.set_ylim(0, 1.05*(keyparams['opex_total']/keyparams['heat_prod_total']).max())\n",
    "    ax2.set_ylabel('Operational cost per heat produce in €/MWh', color='red')\n",
    "    ax2.axhline(opex_total_base/heat_prod_total_base, color='red')\n",
    "\n",
    "    ax[i].grid()\n",
    "    ax[i].set_ylim(0, 1.05*perf['total_time'].max())\n",
    "    ax[i].set_xticks(nr_periods, labels=nr_periods)\n",
    "    ax[i].set_title(f'{hour_pp} hours per period')\n",
    "    ax[i].set_xlabel('Number of typical periods')\n",
    "    ax[i].set_ylabel('Runtime in s')\n",
    "    ax[i].legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_axs = len(hours_per_period)\n",
    "fig, ax = plt.subplots(nr_axs, 1, figsize=(12, 3*nr_axs), sharey=True)\n",
    "\n",
    "for i, hour_pp in enumerate(hours_per_period):\n",
    "    _hp = ax[i].bar(nr_periods, keyparams.loc[(hour_pp, nr_periods), 'hp_share'], label='heat pump')\n",
    "    _gb = ax[i].bar(nr_periods, keyparams.loc[(hour_pp, nr_periods), 'gb_share'], label='gas boiler', bottom=keyparams.loc[(hour_pp, nr_periods), 'hp_share'])\n",
    "    _slack = ax[i].bar(nr_periods, keyparams.loc[(hour_pp, nr_periods), 'slack_share'], label='heat slack', bottom=keyparams.loc[(hour_pp, nr_periods), 'hp_share']+keyparams.loc[(hour_pp, nr_periods), 'gb_share'])\n",
    "    ax[i].axhline(heat_prod_shares_base[\"heat pump to heat bus\"], color=_hp[0]._facecolor)\n",
    "    ax[i].axhline(heat_prod_shares_base[\"gas boiler to heat bus\"] + heat_prod_shares_base[\"heat pump to heat bus\"], color=_gb[0]._facecolor)\n",
    "    ax[i].axhline(heat_prod_shares_base[\"heat slack to heat bus\"] + heat_prod_shares_base[\"gas boiler to heat bus\"] + heat_prod_shares_base[\"heat pump to heat bus\"], color=_slack[0]._facecolor)\n",
    "\n",
    "    ax[i].grid()\n",
    "    ax[i].set_xticks(nr_periods, labels=nr_periods)\n",
    "    ax[i].set_title(f'{hour_pp} hours per period')\n",
    "    ax[i].set_xlabel('Number of typical periods')\n",
    "    ax[i].set_ylabel('Share of heat production')\n",
    "    ax[i].legend(loc='upper left')\n",
    "    ax[i].set_axisbelow(True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_axs = len(hours_per_period)\n",
    "fig, ax = plt.subplots(nr_axs, 1, figsize=(12, 3*nr_axs), sharey=True)\n",
    "\n",
    "reference = heat_prod_shares_base.copy() * heat_prod_total_base\n",
    "reference[\"lcoh\"] = opex_total_base / heat_prod_total_base\n",
    "# reference = reference.rename({\"heat pump to heat bus\": \"hp_total\", \"gas boiler to heat bus\": \"gb_total\", \"heat slack to heat bus\": \"slack_total\"})\n",
    "reference = reference.rename({\"heat pump to heat bus\": \"hp_total\", \"gas boiler to heat bus\": \"gb_total\", \"heat slack to heat bus\": \"slack_total\"})\n",
    "keyparams[\"lcoh\"] = keyparams[\"opex_total\"] / keyparams[\"heat_prod_total\"]\n",
    "\n",
    "val_min = -0.3\n",
    "val_max = +0.3\n",
    "values = np.linspace(val_min, val_max, 4)\n",
    "\n",
    "\n",
    "cols = [\"hp_share\", \"gb_share\"]\n",
    "for col in cols:\n",
    "    keyparams[col.replace(\"share\", \"total\")] = keyparams[col] * heat_prod_total_base\n",
    "\n",
    "\n",
    "for i, hour_pp in enumerate(hours_per_period):\n",
    "    for k, col in enumerate(['lcoh'] + [col.replace(\"share\", \"total\") for col in cols]):\n",
    "        value = keyparams.loc[(hour_pp, nr_periods), col]\n",
    "        ax[i].bar(nr_periods + values[k], (value - reference[col]) / reference[col], label=col, width=0.2)\n",
    "\n",
    "\n",
    "# for i, hour_pp in enumerate(hours_per_period):\n",
    "#     for k, col in enumerate(['lcoh']):\n",
    "#         value = keyparams.loc[(hour_pp, nr_periods), col]\n",
    "#         ax[i].bar(nr_periods + values[k], (value - reference[col]), label=col, width=0.2)\n",
    "\n",
    "# for i, hour_pp in enumerate(hours_per_period):\n",
    "#     for k, col in enumerate(['hp_share', 'gb_share', 'slack_share']):\n",
    "#         value = keyparams.loc[(hour_pp, nr_periods), col]\n",
    "#         ax[i].bar(nr_periods + values[k], (value - reference[col]), label=col, width=0.2)\n",
    "\n",
    "    ax[i].set_xticks(nr_periods, labels=nr_periods)\n",
    "    ax[i].set_title(f'{hour_pp} hours per period')\n",
    "    ax[i].set_ylabel('Absolute difference in heat shares to reference')\n",
    "    ax[i].grid()\n",
    "    ax[i].legend()\n",
    "    ax[i].set_axisbelow(True)\n",
    "    ax[i].set_ylim([-.03, +.03])\n",
    "\n",
    "ax[-1].set_xlabel('Number of typical periods')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "nr_axs = len(hours_per_period)\n",
    "fig, ax = plt.subplots(nr_axs, 3, figsize=(12, 3*nr_axs))\n",
    "\n",
    "for i, hour_pp in enumerate(hours_per_period):\n",
    "    for nr_period in nr_periods:\n",
    "        flows = ['heat pump to heat bus', 'gas boiler to heat bus', 'heat slack to heat bus']\n",
    "        units = [f.replace(' to heat bus', '') for f in flows]\n",
    "        unit_data_sorted = pd.DataFrame(\n",
    "            np.sort(unit_data_all[hour_pp][nr_period][flows].values, axis=0)[::-1], columns=units\n",
    "            )\n",
    "        for u, unit in enumerate(units):\n",
    "            ax[i][u].plot(unit_data_sorted[unit], c=mpl.cm.plasma(nr_period/max(nr_periods)))\n",
    "\n",
    "    # heat pump\n",
    "\n",
    "    for u, unit in enumerate(units):\n",
    "        ax[i][u].grid()\n",
    "        ax[i][u].set_title(f'{hour_pp} hours per period\\n{unit}')\n",
    "        ax[i][u].set_xlabel('Hour of year')\n",
    "        ax[i][u].set_ylabel('Hourly heat production in MWh')\n",
    "\n",
    "        ax[i][u].plot(unitdata_base[f\"{unit} to heat bus\"].sort_values(ascending=False).values)\n",
    "\n",
    "fig.suptitle('Ordered yearly load duration curves by unit (warmer == more typical periods)\\n')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_axs = len(hours_per_period)\n",
    "fig, ax = plt.subplots(nr_axs, 1, figsize=(12, 3*nr_axs), sharey=True)\n",
    "\n",
    "flows = ['heat pump to heat bus', 'gas boiler to heat bus', 'heat slack to heat bus']\n",
    "units = [f.replace(' to heat bus', '') for f in flows]\n",
    "unitdata_base_sorted = pd.DataFrame(\n",
    "    np.sort(unitdata_base[flows].values, axis=0)[::-1], columns=units\n",
    ")\n",
    "# unitdata_base_sorted\n",
    "# unit_data_sorted\n",
    "\n",
    "for i, hour_pp in enumerate(hours_per_period):\n",
    "    per_period_df = pd.DataFrame(columns=units, index=nr_periods)\n",
    "    for nr_period in nr_periods:\n",
    "        unit_data_sorted = pd.DataFrame(\n",
    "            np.sort(unit_data_all[hour_pp][nr_period][flows].values, axis=0)[::-1], columns=units\n",
    "        )\n",
    "        number_hours = len(unit_data_sorted)\n",
    "        diff_rel = (unit_data_sorted - unitdata_base_sorted.iloc[:number_hours]).sum()\n",
    "\n",
    "        per_period_df.loc[nr_period, units] = diff_rel\n",
    "\n",
    "    locations = [-.25, 0, +.25]\n",
    "    for k, unit in enumerate(units):\n",
    "        ax[i].bar(per_period_df.index + locations[k], per_period_df[unit], width=0.25, label=unit)\n",
    "\n",
    "\n",
    "    ax[i].set_xticks(nr_periods, labels=nr_periods)\n",
    "    ax[i].set_title(f'{hour_pp} hours per period')\n",
    "    ax[i].set_ylabel('Total difference in duration curve')\n",
    "    ax[i].grid()\n",
    "    ax[i].legend()\n",
    "    ax[i].set_axisbelow(True)\n",
    "\n",
    "    ax2 = ax[i].twinx()\n",
    "    per_period_df.cumsum().plot.line(ax=ax2, legend=False)\n",
    "    ax2.set_ylabel(\"Cumulative difference\")\n",
    "    ax2.set_ylim([-1, 2])\n",
    "\n",
    "ax[-1].set_xlabel('Number of typical periods')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_period_df.cumsum().plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_axs = len(hours_per_period)\n",
    "fig, ax = plt.subplots(nr_axs, 1, figsize=(12, 3*nr_axs))\n",
    "\n",
    "for i, hour_pp in enumerate(hours_per_period):\n",
    "    ax[i].bar(nr_periods, keyparams.loc[(hour_pp, nr_periods), 'disp_diff_total'] / heat_prod_total_base)\n",
    "\n",
    "    ax[i].grid(axis='y')\n",
    "    # ax[i].set_ylim(0, 1.2)\n",
    "    ax[i].set_xticks(nr_periods, labels=nr_periods)\n",
    "    ax[i].set_title(f'{hour_pp} hours per period')\n",
    "    ax[i].set_xlabel('Number of typical periods')\n",
    "    ax[i].set_ylabel('Gesamte absolute Abweichung\\ndes Anlageneinsatzes in MWh')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_demand_total = unitdata_base[\"heat bus to heat demand\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_demand_actual = {}\n",
    "for hour_pp in unit_data_all:\n",
    "    heat_demand_actual[hour_pp] = {}\n",
    "    for nr_period, df in unit_data_all[hour_pp].items():\n",
    "        heat_demand_actual[hour_pp][nr_period] = df[\"heat bus to heat demand\"].sum()\n",
    "        print(hour_pp, nr_period, (heat_demand_actual[hour_pp][nr_period] - heat_demand_total) / heat_demand_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsam_solph_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
